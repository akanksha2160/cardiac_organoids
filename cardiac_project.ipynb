{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53856913-baaf-4dc6-a2ef-aab0a2d91a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from flask import Flask, request, render_template\n",
    "import os\n",
    "from PIL import Image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbce965-9ad3-4ec6-a4e9-11f574b2b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "def preprocess_image(img_path, target_size, preprocess_input_func):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input_func(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8dbcc1c-0142-4273-aa9a-20e39421af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained Models and Modify for Binary Classification\n",
    "def build_model(base_model, preprocess_input_func):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model, preprocess_input_func\n",
    "\n",
    "# Load models\n",
    "resnet_base = ResNet50(weights='imagenet', include_top=False)\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False)\n",
    "inception_base = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "resnet_model, resnet_preprocess_func = build_model(resnet_base, resnet_preprocess)\n",
    "vgg_model, vgg_preprocess_func = build_model(vgg_base, vgg_preprocess)\n",
    "inception_model, inception_preprocess_func = build_model(inception_base, inception_preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702a0358-f5cd-47d3-b6e0-2631d9e2c560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-1-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-1-2.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-10-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-11-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-11-2,3.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-12-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-12-2.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-13-1,2.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-14-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-15-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-15-3.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-15-4.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-16-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-16-2.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-2-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-2-2.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-2-3.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-3-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-3-2.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-4-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-4-2.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-5-1,2,3.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-6-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-6-2.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-7-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-7-2.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-7-3,4.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-8-1.mp4\n",
      "Removing non-image file: C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating\\D9-8-3,4.mp4\n",
      "Found 29 images belonging to 2 classes.\n",
      "Found 7 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 132s/step - accuracy: 0.4138 - loss: 0.8706 - val_accuracy: 0.8571 - val_loss: 0.7729\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28s/step - accuracy: 0.8621 - loss: 0.8293 - val_accuracy: 0.2857 - val_loss: 0.7056\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41s/step - accuracy: 1.0000 - loss: 9.5252e-04 - val_accuracy: 0.1429 - val_loss: 4.3194\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26s/step - accuracy: 1.0000 - loss: 1.4736e-05 - val_accuracy: 0.1429 - val_loss: 12.8189\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28s/step - accuracy: 1.0000 - loss: 2.3014e-05 - val_accuracy: 0.1429 - val_loss: 31.3720\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 1.0000 - loss: 1.7102e-04 - val_accuracy: 0.1429 - val_loss: 59.9754\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26s/step - accuracy: 1.0000 - loss: 1.7325e-04 - val_accuracy: 0.1429 - val_loss: 109.9013\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.1429 - val_loss: 175.2945\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step - accuracy: 1.0000 - loss: 5.1306e-04 - val_accuracy: 0.1429 - val_loss: 251.1937\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step - accuracy: 1.0000 - loss: 1.6982e-04 - val_accuracy: 0.1429 - val_loss: 331.1806\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 87s/step - accuracy: 0.8621 - loss: 0.5687 - val_accuracy: 0.8571 - val_loss: 16.2050\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85s/step - accuracy: 0.8621 - loss: 17.7507 - val_accuracy: 0.8571 - val_loss: 0.5759\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 78s/step - accuracy: 0.8621 - loss: 0.5693 - val_accuracy: 0.8571 - val_loss: 0.4210\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80s/step - accuracy: 0.8621 - loss: 0.3999 - val_accuracy: 0.8571 - val_loss: 0.4135\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81s/step - accuracy: 0.8621 - loss: 0.3939 - val_accuracy: 0.1429 - val_loss: 2.6967\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m791s\u001b[0m 791s/step - accuracy: 0.1379 - loss: 2.6535 - val_accuracy: 0.8571 - val_loss: 0.4151\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79s/step - accuracy: 0.8621 - loss: 0.3922 - val_accuracy: 0.8571 - val_loss: 0.4421\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 77s/step - accuracy: 0.8621 - loss: 0.4131 - val_accuracy: 0.8571 - val_loss: 0.4217\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 78s/step - accuracy: 0.8621 - loss: 0.3969 - val_accuracy: 0.8571 - val_loss: 0.4095\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76s/step - accuracy: 0.8621 - loss: 0.3938 - val_accuracy: 0.8571 - val_loss: 0.4085\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 121s/step - accuracy: 0.1379 - loss: 0.9954 - val_accuracy: 0.8571 - val_loss: 3.0339\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step - accuracy: 0.8621 - loss: 2.3520 - val_accuracy: 0.8571 - val_loss: 3.6294\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8621 - loss: 0.1949 - val_accuracy: 0.8571 - val_loss: 4.1411\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 0.9655 - loss: 0.0843 - val_accuracy: 0.8571 - val_loss: 4.9505\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 0.0711 - val_accuracy: 0.8571 - val_loss: 3.8781\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 0.0448 - val_accuracy: 0.8571 - val_loss: 1.6345\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0254 - val_accuracy: 0.8571 - val_loss: 0.1439\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 0.1446\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.4286 - val_loss: 1.2270\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.1429 - val_loss: 3.7355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17d2618dd90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Generators and Training\n",
    "def remove_non_image_files(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            img = Image.open(file_path)\n",
    "            img.verify()  # Verify that it is, in fact, an image\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            print(f'Removing non-image file: {file_path}')\n",
    "            os.remove(file_path)\n",
    "\n",
    "# Run this on both beating and non_beating directories\n",
    "remove_non_image_files(r'C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\beating')\n",
    "remove_non_image_files(r'C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data\\non_beating')\n",
    "\n",
    "# Data augmentation and data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\kakan\\OneDrive\\Desktop\\cardiac project\\data',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation')\n",
    "\n",
    "# Train models\n",
    "resnet_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
    "vgg_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
    "inception_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a2767a-84ae-46c0-a69c-a49896c2ded0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#Save Models\n",
    "resnet_model.save('resnet_model.h5')\n",
    "vgg_model.save('vgg_model.h5')\n",
    "inception_model.save('inception_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21cfcfce-008d-4147-aaa9-68a9d687b56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug: * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "#Create Flask App for User Interface\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load models\n",
    "resnet_model = tf.keras.models.load_model('resnet_model.h5')\n",
    "vgg_model = tf.keras.models.load_model('vgg_model.h5')\n",
    "inception_model = tf.keras.models.load_model('inception_model.h5')\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if 'file' not in request.files:\n",
    "        return 'No file part'\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return 'No selected file'\n",
    "    if file:\n",
    "        img_path = os.path.join('uploads', file.filename)\n",
    "        file.save(img_path)\n",
    "\n",
    "        img_resnet = preprocess_image(img_path, (224, 224), resnet_preprocess_func)\n",
    "        img_vgg = preprocess_image(img_path, (224, 224), vgg_preprocess_func)\n",
    "        img_inception = preprocess_image(img_path, (224, 224), inception_preprocess_func)\n",
    "\n",
    "        prediction_resnet = resnet_model.predict(img_resnet)[0][0]\n",
    "        prediction_vgg = vgg_model.predict(img_vgg)[0][0]\n",
    "        prediction_inception = inception_model.predict(img_inception)[0][0]\n",
    "\n",
    "        # Majority vote\n",
    "        predictions = [prediction_resnet, prediction_vgg, prediction_inception]\n",
    "        final_prediction = np.mean(predictions) > 0.5\n",
    "\n",
    "        result = 'Beating' if final_prediction else 'Non-beating'\n",
    "        return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6c92e-b263-4a40-b419-46963398e98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3778b42-827b-4f15-b310-b06832ae8528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b58802-844f-436f-a956-d90eac3f2312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
